{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './CCPD2019-dl1'\n",
    "\n",
    "photos = os.listdir(PATH+'/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AYX440\n",
      "original shape (92, 217, 3)\n",
      "resised shape (128, 256, 3)\n",
      "black/white shape (128, 256)\n"
     ]
    }
   ],
   "source": [
    "# Let's show our data\n",
    "num = 0\n",
    "img = cv.imread(PATH+'/test/'+photos[num])\n",
    "print(photos[num].split('-')[1].split('.')[0][1:])\n",
    "print('original shape', img.shape)\n",
    "\n",
    "# resising\n",
    "dim = (256, 128)\n",
    "img_resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "print('resised shape', img_resized.shape)\n",
    "\n",
    "# converting to black/white\n",
    "img_grey = cv.cvtColor(img_resized, cv.COLOR_BGR2GRAY)\n",
    "print('black/white shape', img_grey.shape)\n",
    "\n",
    "# show pic\n",
    "cv.imshow('image', img_grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199981/199981 [01:00<00:00, 3329.07it/s]\n",
      "100%|██████████| 9999/9999 [00:03<00:00, 2754.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "data_train = get_data(PATH+'/train/')\n",
    "data_test = get_data(PATH+'/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, 79)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataLoaders\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(data_train, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(data_test, batch_size=128, shuffle=True)\n",
    "\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    num = 2\n",
    "    print(x[num].shape)\n",
    "    print(y[num].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 512\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "output_size = len(available_characters) + 1 # output_size = 37\n",
    "lr = 0.5*10**(-4)\n",
    "\n",
    "model = CRNN(input_size, hidden_size, num_layers, output_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8,647,397 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training model\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 2\n",
    "CLIP = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, device, train_dataloader, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, device, test_dataloader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), './best-val-model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): CNN(\n",
       "    (block_0): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "    (block_1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "    (block_2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (block_3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(512, 512, kernel_size=(4, 3), stride=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (rnn): LSTM(\n",
       "    (rnn): LSTM(512, 256, num_layers=2, bidirectional=True)\n",
       "    (embedding): Linear(in_features=512, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load our pretrained weights\n",
    "\n",
    "model.load_state_dict(torch.load('./model_1.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [03:01<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy  97.51 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check accuracy on test data\n",
    "\n",
    "acc = 0\n",
    "for img, text in tqdm(test_dataloader):\n",
    "    pred = model(img)\n",
    "    acc += accuracy(pred, text)\n",
    "\n",
    "print('test accuracy ', round(acc/len(test_dataloader)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [03:02<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test CER metric  99.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check CER metric on test data\n",
    "\n",
    "cer_met = 0\n",
    "for img, text in tqdm(test_dataloader):\n",
    "    pred = model(img)\n",
    "    cer_met += CER_metric(pred, text)\n",
    "\n",
    "print('test CER metric ', round(cer_met.item()/len(test_dataloader)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVK308\n",
      "original shape (116, 344, 3)\n",
      "new image shape (128, 256)\n",
      "pred shape torch.Size([1, 37, 6])\n",
      "pred text avk308\n"
     ]
    }
   ],
   "source": [
    "# Let's check our model on the different photo\n",
    "\n",
    "num = 0\n",
    "path = './Photo/'\n",
    "photos_test = os.listdir(path)\n",
    "img = cv.imread(path+photos_test[num])\n",
    "print(photos_test[num].split('.')[0])\n",
    "print('original shape', img.shape)\n",
    "dim = (256, 128)\n",
    "img_resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "img_grey = cv.cvtColor(img_resized, cv.COLOR_BGR2GRAY)\n",
    "print('new image shape', img_grey.shape)\n",
    "\n",
    "pred = model(torch.from_numpy(img_grey).float().unsqueeze(0))\n",
    "print('pred shape', pred.shape)\n",
    "print('pred text', decoder_text(pred)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "et2",
   "language": "python",
   "name": "et2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
